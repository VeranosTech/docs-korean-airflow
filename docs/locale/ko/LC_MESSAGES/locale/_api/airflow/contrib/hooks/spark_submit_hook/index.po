# SOME DESCRIPTIVE TITLE.
# Copyright (C)
# This file is distributed under the same license as the Airflow package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2019.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Airflow 1.10.1\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2019-04-03 17:47+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.6.0\n"

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:4
msgid ":mod:`airflow.contrib.hooks.spark_submit_hook`"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:15
msgid "Module Contents"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:24
msgid ""
"Bases::class:`airflow.hooks.base_hook.BaseHook`, "
":class:`airflow.utils.log.logging_mixin.LoggingMixin`"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:28
msgid ""
"This hook is a wrapper around the spark-submit binary to kick off a "
"spark-submit job. It requires that the \"spark-submit\" binary is in the "
"PATH or the spark_home to be supplied."
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst
msgid "Parameters"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:32
msgid "Arbitrary Spark configuration properties"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:34
msgid ""
"The connection id as configured in Airflow administration. When an "
"invalid connection_id is supplied, it will default to yarn."
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:37
msgid ""
"Upload additional files to the executor running the job, separated by a "
"comma. Files will be placed in the working directory of each executor. "
"For example, serialized objects."
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:41
msgid "Additional python files used by the job, can be .zip, .egg or .py."
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:45
msgid "Additional, driver-specific, classpath settings."
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:47
msgid "Submit additional jars to upload and place them in executor classpath."
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:49
msgid "the main class of the Java application"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:51
msgid ""
"Comma-separated list of maven coordinates of jars to include on the "
"driver and executor classpaths"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:54
msgid ""
"Comma-separated list of maven coordinates of jars to exclude while "
"resolving the dependencies provided in 'packages'"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:57
msgid ""
"Comma-separated list of additional remote repositories to search for the "
"maven coordinates given with 'packages'"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:60
msgid ""
"(Standalone & Mesos only) Total cores for all executors (Default: all the"
" available cores on the worker)"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:63
msgid ""
"(Standalone, YARN and Kubernetes only) Number of cores per executor "
"(Default: 2)"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:66
msgid "Memory per executor (e.g. 1000M, 2G) (Default: 1G)"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:68
msgid "Memory allocated to the driver (e.g. 1000M, 2G) (Default: 1G)"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:70
msgid "Full path to the file that contains the keytab"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:72
msgid "The name of the kerberos principal used for keytab"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:74
msgid "Name of the job (default airflow-spark)"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:76
msgid "Number of executors to launch"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:78
msgid "Arguments for the application being submitted"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:80
msgid "Environment variables for spark-submit. It supports yarn and k8s mode too."
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:83
msgid "Whether to pass the verbose flag to spark-submit process for debugging"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:85
msgid "The command to use for spark submit. Some distros may use spark2-submit."
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst
msgid "param"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:43
msgid ""
"archives: Archives that spark should unzip (and possibly tag with #ALIAS)"
" into the application working directory."
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:98
msgid ""
"Determines whether or not this hook should poll the spark driver status "
"through subsequent spark-submit status requests after the initial spark-"
"submit request :return: if the driver status should be tracked"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:130
msgid ""
"Construct the spark-submit command to execute. :param application: "
"command to append to the spark-submit command :type application: str "
":return: full command to be executed"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:142
msgid "Construct the command to poll the driver status."
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst
msgid "Returns"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:144
msgid "full command to be executed"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:153
msgid "Remote Popen to execute the spark-submit job"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:155
msgid "Submitted application, jar or py file"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:157
msgid "extra arguments to Popen (see subprocess.Popen)"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:166
msgid "Processes the log files and extracts useful information out of it."
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:168
msgid ""
"If the deploy-mode is 'client', log the output of the submit command as "
"those are the output logs of the Spark worker directly."
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:171
msgid ""
"Remark: If the driver needs to be tracked for its status, the log-level "
"of the spark deploy needs to be at least INFO "
"(log4j.logger.org.apache.spark.deploy=INFO)"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:174
#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:185
msgid "An iterator which iterates over the input of the subprocess"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:183
msgid "parses the logs of the spark driver status query process"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:194
msgid ""
"Polls the driver based on self._driver_id to get the status. Finish "
"successfully when the status is FINISHED. Finish failed when the status "
"is ERROR/UNKNOWN/KILLED/FAILED."
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:198
msgid "Possible status:"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:200
msgid "SUBMITTED"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:201
msgid "Submitted but not yet scheduled on a worker"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:202
msgid "RUNNING"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:203
msgid "Has been allocated to a worker to run"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:204
msgid "FINISHED"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:205
msgid "Previously ran and exited cleanly"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:207
msgid "RELAUNCHING"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:207
msgid ""
"Exited non-zero or due to worker failure, but has not yet started running"
" again"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:210
msgid "UNKNOWN"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:210
msgid ""
"The status of the driver is temporarily not known due to master failure "
"recovery"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:212
msgid "KILLED"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:213
msgid "A user manually killed this driver"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:214
msgid "FAILED"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:215
msgid "The driver exited non-zero and was not supervised"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:217
msgid "ERROR"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:217
msgid ""
"Unable to run or restart due to an unrecoverable error (e.g. missing jar "
"file)"
msgstr ""

#: ../../_api/airflow/contrib/hooks/spark_submit_hook/index.rst:227
msgid ""
"Construct the spark-submit command to kill a driver. :return: full "
"command to kill a driver"
msgstr ""

