# SOME DESCRIPTIVE TITLE.
# Copyright (C)
# This file is distributed under the same license as the Airflow package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2019.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Airflow 1.10.1\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2019-04-03 17:47+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.6.0\n"

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:4
msgid ":mod:`airflow.contrib.hooks.bigquery_hook`"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:10
msgid ""
"This module contains a BigQuery Hook, as well as a very basic PEP 249 "
"implementation for BigQuery."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:22
msgid "Module Contents"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:31
msgid ""
"Bases::class:`airflow.contrib.hooks.gcp_api_base_hook.GoogleCloudBaseHook`,"
" :class:`airflow.hooks.dbapi_hook.DbApiHook`"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:35
msgid ""
"Interact with BigQuery. This hook uses the Google Cloud Platform "
"connection."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:57
msgid "Returns a BigQuery PEP 249 connection object."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:66
msgid "Returns a BigQuery service object."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:75
msgid ""
"Insertion is currently unsupported. Theoretically, you could use "
"BigQuery's streaming API to insert rows into a table, but this hasn't "
"been implemented."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:86
msgid ""
"Returns a Pandas DataFrame for the results produced by a BigQuery query. "
"The DbApiHook method must be overridden because Pandas doesn't support "
"PEP 249 connections, except for SQLite. See:"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:90
msgid ""
"https://github.com/pydata/pandas/blob/master/pandas/io/sql.py#L447 "
"https://github.com/pydata/pandas/issues/6900"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst
msgid "Parameters"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:93
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:412
msgid "The BigQuery SQL to execute."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:95
msgid ""
"The parameters to render the SQL query with (not used, leave to override "
"superclass method)"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:98
msgid ""
"Dialect of BigQuery SQL â€“ legacy SQL or standard SQL defaults to use "
"`self.use_legacy_sql` if not specified"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:109
msgid "Checks for the existence of a table in Google BigQuery."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:111
msgid ""
"The Google cloud project in which to look for the table. The connection "
"supplied to the hook must provide access to the specified project."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:115
msgid "The name of the dataset in which to look for the table."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:118
msgid "The name of the table to check the existence of."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:132
msgid "Bases::class:`pandas_gbq.gbq.GbqConnector`"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:136
msgid ""
"This connector behaves identically to GbqConnector (from Pandas), except "
"that it allows the service to be injected, and disables a call to "
"self.get_credentials(). This allows Airflow to use BigQuery with Pandas "
"without forcing a three legged OAuth connection. Instead, we can inject "
"service account credentials into the binding."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:155
msgid "Bases::class:`object`"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:159
msgid ""
"BigQuery does not have a notion of a persistent connection. Thus, these "
"objects are small stateless factories for cursors, which do all the real "
"work."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:172
msgid "BigQueryConnection does not have anything to close."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:181
msgid "BigQueryConnection does not support transactions."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:190
msgid "Return a new :py:class:`Cursor` object using the connection."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:210
msgid "Bases::class:`airflow.utils.log.logging_mixin.LoggingMixin`"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:214
msgid ""
"The BigQuery base cursor contains helper methods to execute queries "
"against BigQuery. The methods can be used directly by operators, in cases"
" where a PEP 249 cursor isn't needed."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:227
msgid ""
"Creates a new, empty table in the dataset. To create a view, which is "
"defined by a SQL query, parse a dictionary to 'view' kwarg"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:230
msgid "The project to create the table into."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:232
msgid "The dataset to create the table into."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:234
msgid "The Name of the table to be created."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:236
msgid ""
"If set, the schema field list as defined here: "
"https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs#configuration.load.schema"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:239
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:337
msgid "a dictionary containing labels for the table, passed to BigQuery"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:242
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:263
msgid "**Example**: ::"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:247
msgid ""
"configure optional time partitioning fields i.e. partition by field, type"
" and expiration as per API specifications.  .. seealso::     "
"https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#timePartitioning"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:247
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:464
msgid ""
"configure optional time partitioning fields i.e. partition by field, type"
" and expiration as per API specifications."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:251
msgid "https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#timePartitioning"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:253
msgid ""
"[Optional] The fields used for clustering. Must be specified with "
"time_partitioning, data in the table will be first partitioned and "
"subsequently clustered. "
"https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#clustering.fields"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:258
msgid ""
"[Optional] A dictionary containing definition for the view. If set, it "
"will create a view instead of a table: "
"https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#view"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst
msgid "Returns"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:270
msgid "None"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:279
msgid ""
"Creates a new external table in the dataset with the data in Google Cloud"
" Storage. See here:"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:282
msgid "https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#resource"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:284
msgid "for more details about these parameters."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:286
msgid ""
"The dotted ``(<project>.|<project>:)<dataset>.<table>($<partition>)`` "
"BigQuery table name to create external table. If ``<project>`` is not "
"included, project will be the project defined in the connection json."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:292
msgid ""
"The schema field list as defined here: "
"https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#resource"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:295
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:570
msgid ""
"The source Google Cloud Storage URI (e.g. gs://some-bucket/some-"
"file.txt). A single wild per-object name can be used."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:299
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:500
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:574
msgid "File format to export."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:301
msgid ""
"Try to detect schema and format options automatically. Any option "
"specified explicitly will be honored."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:304
msgid ""
"[Optional] The compression type of the data source. Possible values "
"include GZIP and NONE. The default value is NONE. This setting is ignored"
" for Google Cloud Bigtable, Google Cloud Datastore backups and Avro "
"formats."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:310
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:590
msgid ""
"[Optional] Indicates if BigQuery should allow extra values that are not "
"represented in the table schema. If true, the extra values are ignored. "
"If false, records with extra columns are treated as bad records, and if "
"there are too many bad records, an invalid error is returned in the job "
"result."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:316
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:584
msgid ""
"The maximum number of bad records that BigQuery can ignore when running "
"the job."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:319
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:578
msgid "Number of rows to skip when loading from a CSV."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:321
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:582
msgid "The delimiter to use when loading from a CSV."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:323
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:587
msgid "The value that is used to quote data sections in a CSV file."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:326
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:596
msgid "Whether to allow quoted newlines (true) or not (false)."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:329
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:599
msgid ""
"Accept rows that are missing trailing optional columns. The missing "
"values are treated as nulls. If false, records with missing trailing "
"columns are treated as bad records, and if there are too many bad "
"records, an invalid error is returned in the job result. Only applicable "
"when soure_format is CSV."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:335
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:608
msgid "configure optional fields specific to the source format"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:347
msgid ""
"Patch information in an existing table. It only updates fileds that are "
"provided in the request object."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:350
msgid ""
"Reference: "
"https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/patch"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:352
msgid "The dataset containing the table to be patched."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:354
msgid "The Name of the table to be patched."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:356
msgid "The project containing the table to be patched."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:358
msgid "[Optional] A user-friendly description of this table."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:360
msgid ""
"[Optional] The time when this table expires, in milliseconds since the "
"epoch."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:363
msgid ""
"[Optional] A dictionary containing properties of a table stored outside "
"of BigQuery."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:366
msgid "[Optional] A descriptive name for this table."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:368
msgid "[Optional] A dictionary containing labels associated with this table."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:370
msgid ""
"[Optional] If set, the schema field list as defined here: "
"https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs#configuration.load.schema"
" The supported schema modifications and unsupported schema modification "
"are listed here: https://cloud.google.com/bigquery/docs/managing-table-"
"schemas **Example**: ::      schema=[{\"name\": \"emp_name\", \"type\": "
"\"STRING\", \"mode\": \"REQUIRED\"},                    {\"name\": "
"\"salary\", \"type\": \"INTEGER\", \"mode\": \"NULLABLE\"}]"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:370
msgid ""
"[Optional] If set, the schema field list as defined here: "
"https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs#configuration.load.schema"
" The supported schema modifications and unsupported schema modification "
"are listed here: https://cloud.google.com/bigquery/docs/managing-table-"
"schemas **Example**: ::"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:380
msgid ""
"[Optional] A dictionary containing time-based partitioning definition for"
" the table."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:383
msgid ""
"[Optional] A dictionary containing definition for the view. If set, it "
"will patch a view instead of a table: "
"https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#view "
"**Example**: ::      view = {         \"query\": \"SELECT * FROM `test-"
"project-id.test_dataset_id.test_table_prefix*` LIMIT 500\",         "
"\"useLegacySql\": False     }"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:383
msgid ""
"[Optional] A dictionary containing definition for the view. If set, it "
"will patch a view instead of a table: "
"https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#view "
"**Example**: ::"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:394
msgid ""
"[Optional] If true, queries over the this table require a partition "
"filter. If false, queries over the table"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:405
msgid ""
"Executes a BigQuery SQL query. Optionally persists results in a BigQuery "
"table. See here:"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:408
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:486
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:552
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:627
msgid "https://cloud.google.com/bigquery/docs/reference/v2/jobs"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:410
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:488
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:522
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:554
msgid "For more details about these parameters."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:414
msgid "The dotted ``<dataset>.<table>`` BigQuery table to save the query results."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:417
msgid "What to do if the table already exists in BigQuery."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:420
msgid "Whether to allow large results."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:422
msgid ""
"If true and query uses legacy SQL dialect, flattens all nested and "
"repeated fields in the query results. ``allowLargeResults`` must be true "
"if this is set to false. For standard SQL queries, this flag is ignored "
"and results are never flattened."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:427
msgid ""
"The User Defined Function configuration for the query. See "
"https://cloud.google.com/bigquery/user-defined-functions for details."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:430
msgid ""
"Whether to use legacy SQL (true) or standard SQL (false). If `None`, "
"defaults to `self.use_legacy_sql`."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:433
msgid ""
"a dictionary that contain params 'configuration' applied for Google "
"BigQuery Jobs API: "
"https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs for "
"example, {'query': {'useQueryCache': False}}. You could use it if you "
"need to provide some params that are not supported by the BigQueryHook "
"like args."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:440
msgid "Positive integer that serves as a multiplier of the basic price."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:443
msgid ""
"Limits the bytes billed for this job. Queries that will have bytes billed"
" beyond this limit will fail (without incurring a charge). If "
"unspecified, this will be set to your project default."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:448
msgid "Specifies whether the job is allowed to create new tables."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:451
msgid ""
"a list of dictionary containing query parameter types and values, passed "
"to BigQuery"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:454
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:506
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:538
msgid "a dictionary containing labels for the job/query, passed to BigQuery"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:457
msgid ""
"Allows the schema of the destination table to be updated as a side effect"
" of the query job."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:460
msgid ""
"Specifies a priority for the query. Possible values include INTERACTIVE "
"and BATCH. The default value is INTERACTIVE."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:467
msgid ""
"Request that the result of this query be stored sorted by one or more "
"columns. This is only available in combination with time_partitioning. "
"The order of columns given determines the sort order."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:471
msgid ""
"The geographic location of the job. Required except for US and EU. See "
"details at "
"https://cloud.google.com/bigquery/docs/locations#specifying_your_location"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:483
msgid ""
"Executes a BigQuery extract command to copy data from BigQuery to Google "
"Cloud Storage. See here:"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:490
msgid "The dotted ``<dataset>.<table>`` BigQuery table to use as the source data."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:493
msgid ""
"The destination Google Cloud Storage URI (e.g. gs://some-bucket/some-"
"file.txt). Follows convention defined here: "
"https://cloud.google.com/bigquery/exporting-data-from-"
"bigquery#exportingmultiple"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:498
msgid "Type of compression to use."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:502
msgid "The delimiter to use when extracting to a CSV."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:504
msgid "Whether to print a header for a CSV file extract."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:517
msgid ""
"Executes a BigQuery copy command to copy data from one BigQuery table to "
"another. See here:"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:520
msgid "https://cloud.google.com/bigquery/docs/reference/v2/jobs#configuration.copy"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:524
msgid ""
"One or more dotted ``(project:|project.)<dataset>.<table>`` BigQuery "
"tables to use as the source data. Use a list if there are multiple source"
" tables. If ``<project>`` is not included, project will be the project "
"defined in the connection json."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:531
msgid ""
"The destination BigQuery table. Format is: "
"``(project:|project.)<dataset>.<table>``"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:534
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:580
msgid "The write disposition if the table already exists."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:536
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:576
msgid "The create disposition if the table doesn't exist."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:549
msgid ""
"Executes a BigQuery load command to load data from Google Cloud Storage "
"to BigQuery. See here:"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:556
msgid ""
"The dotted ``(<project>.|<project>:)<dataset>.<table>($<partition>)`` "
"BigQuery table to load data into. If ``<project>`` is not included, "
"project will be the project defined in the connection json. If a "
"partition is specified the operator will automatically append the data, "
"create a new partition or create a new DAY partitioned table."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:563
msgid ""
"The schema field list as defined here: "
"https://cloud.google.com/bigquery/docs/reference/v2/jobs#configuration.load"
" Required if autodetect=False; optional if autodetect=True."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:567
msgid "Attempt to autodetect the schema for CSV and JSON source files."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:605
msgid ""
"Allows the schema of the destination table to be updated as a side effect"
" of the load job."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:610
msgid ""
"configure optional time partitioning fields i.e. partition by field, type"
" and  expiration as per API specifications."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:613
msgid ""
"Request that the result of this load be stored sorted by one or more "
"columns. This is only available in combination with time_partitioning. "
"The order of columns given determines the sort order."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:625
msgid "Executes a BigQuery SQL query. See here:"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:629
msgid "For more details about the configuration parameter."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:631
msgid ""
"The configuration parameter maps directly to BigQuery's configuration "
"field in the job object. See "
"https://cloud.google.com/bigquery/docs/reference/v2/jobs for details."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:650
msgid "Cancel all started queries that have not yet completed"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:659
msgid ""
"Get the schema for a given datset.table. see "
"https://cloud.google.com/bigquery/docs/reference/v2/tables#resource"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:662
msgid "the dataset ID of the requested table"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:663
msgid "the table ID of the requested table"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:664
msgid "a table schema"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:673
msgid ""
"Get the data of a given dataset.table and optionally with selected "
"columns. see "
"https://cloud.google.com/bigquery/docs/reference/v2/tabledata/list"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:676
msgid "the dataset ID of the requested table."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:677
msgid "the table ID of the requested table."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:678
msgid "the maximum results to return."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:679
msgid ""
"List of fields to return (comma-separated). If unspecified, all fields "
"are returned."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:681
msgid "page token, returned from a previous call, identifying the result set."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:683
msgid "zero based index of the starting row to read."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:684
msgid "map containing the requested rows."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:693
msgid ""
"Delete an existing table from the dataset; If the table does not exist, "
"return an error unless ignore_if_missing is set to True."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:697
msgid ""
"A dotted ``(<project>.|<project>:)<dataset>.<table>`` that indicates "
"which table will be deleted."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:701
msgid "if True, then return success even if the requested table does not exist."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:713
msgid ""
"creates a new, empty table in the dataset; If the table already exists, "
"update the existing table. Since BigQuery does not natively allow table "
"upserts, this is not an atomic operation."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:718
msgid "the dataset to upsert the table into."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:720
msgid ""
"a table resource. see "
"https://cloud.google.com/bigquery/docs/reference/v2/tables#resource"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:723
msgid ""
"the project to upsert the table into.  If None, project will be "
"self.project_id."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:734
msgid ""
"Grant authorized view access of a dataset to a view table. If this view "
"has already been granted access to the dataset, do nothing. This method "
"is not atomic.  Running it may clobber a simultaneous update."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:738
msgid "the source dataset"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:740
msgid "the dataset that the view is in"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:742
msgid "the table of the view"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:744
msgid "the project of the source dataset. If None, self.project_id will be used."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:747
msgid "the project that the view is in. If None, self.project_id will be used."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:750
msgid "the datasets resource of the source dataset."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:759
msgid ""
"Create a new empty dataset: "
"https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets/insert"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:762
msgid ""
"The name of the project where we want to create an empty a dataset. Don't"
" need to provide, if projectId in dataset_reference."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:765
msgid ""
"The id of dataset. Don't need to provide, if datasetId in "
"dataset_reference."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:768
msgid ""
"Dataset reference that could be provided with request body. More info: "
"https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets#resource"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:780
msgid ""
"Delete a dataset of Big query in your project. :param project_id: The "
"name of the project where we have the dataset . :type project_id: str "
":param dataset_id: The dataset to be delete. :type dataset_id: str "
":return:"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:794
msgid ""
"Method returns dataset_resource if dataset exist and raised 404 error if "
"dataset does not exist"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:797
msgid "The BigQuery Dataset ID"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:799
msgid "The GCP Project ID"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:801
msgid ""
"dataset_resource  .. seealso::     For more information, see Dataset "
"Resource content:     "
"https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets#resource"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:801
msgid "dataset_resource"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:804
msgid ""
"For more information, see Dataset Resource content: "
"https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets#resource"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:814
msgid "Method returns full list of BigQuery datasets in the current project"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:817
msgid ""
"For more information, see: "
"https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets/list"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:820
msgid "Google Cloud Project for which you try to get all datasets"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:823
msgid ""
"datasets_list  Example of returned datasets_list: ::         {           "
"\"kind\":\"bigquery#dataset\",           \"location\":\"US\",           "
"\"id\":\"your-project:dataset_2_test\",           \"datasetReference\":{"
"              \"projectId\":\"your-project\",              "
"\"datasetId\":\"dataset_2_test\"           }        },        {"
"           \"kind\":\"bigquery#dataset\",           \"location\":\"US\","
"           \"id\":\"your-project:dataset_1_test\",           "
"\"datasetReference\":{              \"projectId\":\"your-project\","
"              \"datasetId\":\"dataset_1_test\"           }        }     ]"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:823
msgid "datasets_list"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:825
msgid "Example of returned datasets_list: ::"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:854
msgid ""
"Method to stream data into BigQuery one record at a time without needing "
"to run a load job"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:858
msgid ""
"For more information, see: "
"https://cloud.google.com/bigquery/docs/reference/rest/v2/tabledata/insertAll"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:861
msgid "The name of the project where we have the table"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:863
msgid "The name of the dataset where we have the table"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:865
msgid "The name of the table"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:867
msgid "the rows to insert"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:871
msgid "**Example or rows**:"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:871
msgid ""
"rows=[{\"json\": {\"a_key\": \"a_value_0\"}}, {\"json\": {\"a_key\": "
"\"a_value_1\"}}]"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:873
msgid ""
"[Optional] Accept rows that contain values that do not match the schema. "
"The unknown values are ignored. The default value  is false, which treats"
" unknown values as errors."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:877
msgid ""
"[Optional] Insert all valid rows of a request, even if invalid rows "
"exist. The default value is false, which causes the entire request to "
"fail if any invalid rows exist."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:881
msgid ""
"[Optional] Force the task to fail if any errors occur. The default value "
"is false, which indicates the task should not fail even if any insertion "
"errors occur."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:897
msgid "Bases::class:`airflow.contrib.hooks.bigquery_hook.BigQueryBaseCursor`"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:901
msgid ""
"A very basic BigQuery PEP 249 cursor implementation. The PyHive PEP 249 "
"implementation was used as a reference:"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:904
msgid ""
"https://github.com/dropbox/PyHive/blob/master/pyhive/presto.py "
"https://github.com/dropbox/PyHive/blob/master/pyhive/common.py"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:914
msgid "The schema description method is not currently implemented."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:924
msgid "By default, return -1 to indicate that this is not supported."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:946
msgid "By default, do nothing"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:955
msgid "Executes a BigQuery query, and returns the job ID."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:957
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:971
msgid "The query to execute."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:959
msgid "Parameters to substitute into the query."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:969
msgid "Execute a BigQuery query multiple times with different parameters."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:973
msgid "List of dictionary parameters to substitute into the query."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:984
msgid "Fetch the next row of a query result set."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:993
msgid ""
"Helper method for fetchone, which returns the next row from a buffer. If "
"the buffer is empty, attempts to paginate through the result set for the "
"next page, and load it into the buffer."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:1004
msgid ""
"Fetch the next set of rows of a query result, returning a sequence of "
"sequences (e.g. a list of tuples). An empty sequence is returned when no "
"more rows are available. The number of rows to fetch per call is "
"specified by the parameter. If it is not given, the cursor's arraysize "
"determines the number of rows to be fetched. The method should try to "
"fetch as many rows as indicated by the size parameter. If this is not "
"possible due to the specified number of rows not being available, fewer "
"rows may be returned. An :py:class:`~pyhive.exc.Error` (or subclass) "
"exception is raised if the previous call to :py:meth:`execute` did not "
"produce any result set or no call was issued yet."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:1021
msgid ""
"Fetch all (remaining) rows of a query result, returning them as a "
"sequence of sequences (e.g. a list of tuples)."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:1031
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:1040
msgid "Specifies the number of rows to fetch at a time with .fetchmany()"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:1049
#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:1058
msgid "Does nothing by default"
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:1072
msgid "Helper method that binds parameters to a SQL query."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:1085
msgid "Helper method that escapes parameters to a SQL query."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:1098
msgid ""
"Helper method that casts a BigQuery row to the appropriate data types. "
"This is useful because BigQuery returns all fields as strings."
msgstr ""

#: ../../_api/airflow/contrib/hooks/bigquery_hook/index.rst:1134
msgid "function to check expected type and raise error if type is not correct"
msgstr ""

